{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b463e390-be73-4cf3-98e0-82b703074bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f523983c-191a-4557-ac3f-2a6d93af9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(filename,review_col,max_reviews_per_file):\n",
    "    reviews = []\n",
    "    try:\n",
    "        with open(filename, 'r', encoding=\"utf8\") as file:\n",
    "            total_reviews = sum(1 for _ in file)\n",
    "            print(f\"{filename} has {total_reviews - 1} reviews\")\n",
    "            file.seek(0)\n",
    "            my_reader = csv.reader(file, delimiter=',')\n",
    "            next(my_reader, None)\n",
    "            for i, row in enumerate(my_reader):\n",
    "                if i >= max_reviews_per_file:\n",
    "                    break\n",
    "                reviews.append(row[review_col])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7daf80-5bb4-499d-9239-824c5199783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_reviews(reviews):\n",
    "    for i in tqdm(range(len(reviews)), desc=\"Lowercasing\"):\n",
    "        reviews[i] = reviews[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc097bc8-45a3-48c2-9712-102a78b23a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_punctuation(reviews):\n",
    "    punctuation_chars_to_remove = {'.',',','(',')','[',']','`',\"'\",'\"', ';', ':'}\n",
    "    punctuation_chars_to_space = {'_', '-', '–', '\\''}\n",
    "    for i in tqdm(range(len(reviews)), desc=\"Cleaning reviews\"):\n",
    "        for char in punctuation_chars_to_remove:\n",
    "            reviews[i] = reviews[i].replace(char, '')  \n",
    "        for char in punctuation_chars_to_space:\n",
    "            reviews[i] = reviews[i].replace(char, ' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e02e9e6-9a7f-4c35-aca4-eea98a2cafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_extend(reviews,delimeter='.'):\n",
    "    sentences = []\n",
    "    for i in tqdm(range(len(reviews)), desc=f\"Splitting reviews by '{delimeter}'\"):\n",
    "        sentences.extend(reviews[i].split('.'))\n",
    "    reviews = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6fa36f9-7247-4357-b14b-dba6b3bdfdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences_into_words(sentences,delimeter=' '):\n",
    "    for i in tqdm(range(len(sentences)), desc=\"Splitting sentences into words\"):\n",
    "        sentences[i] = sentences[i].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71383c9-5346-40c8-ae99-d70b63c4ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_with_special_symbols(sentences):\n",
    "    special_symbol_mapping = {'&': 'AMP', '#': 'HT', '@': 'AT'}\n",
    "    for sentence in tqdm(sentences, desc=\"Replacing special symbol words\", total=len(sentences)):\n",
    "        for i in range(len(sentence)):\n",
    "            for symbol, token in special_symbol_mapping.items():\n",
    "                if symbol in sentence[i]:\n",
    "                    sentence[i] = f\"{token}_TOKEN\"\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1628d281-7fa9-44ab-afe2-c462314791ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_digit_words(sentences):\n",
    "    digit_symbols = {'%': 'PCT', '$': 'USD', '€': 'EUR'}\n",
    "    for sentence in tqdm(sentences, desc=\"Replacing digit words\", total=len(sentences)):\n",
    "        for i in range(len(sentence)):\n",
    "            word = sentence[i]\n",
    "            if not re.search(r'\\d', word):\n",
    "                continue\n",
    "                \n",
    "            for symbol, token in digit_symbols.items():\n",
    "                if symbol in word:\n",
    "                    sentence[i] = f\"{len(word)}_{token}_DIGIT_TOKEN\"\n",
    "                    break\n",
    "                elif re.match(r'^\\d+$', word):  \n",
    "                    sentence[i] = f\"{len(word)}_DIGIT_TOKEN\"\n",
    "                elif re.search(r'\\d.*[a-zA-Z]|[a-zA-Z].*\\d', word): \n",
    "                    sentence[i] = None  \n",
    "\n",
    "    for sentence in tqdm(sentences, desc=\"Removing None values\", total=len(sentences)):\n",
    "        while None in sentence:\n",
    "            sentence.remove(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b9fa48-df6b-4e08-8417-668e5ed37a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha_numeric(sentences):\n",
    "    for sentence in tqdm(sentences, desc=\"Removing non-alphanumeric words\", total=len(sentences)):\n",
    "        sentence[:] = [word for word in sentence if re.match(r'^[a-zA-Z0-9_]+$', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8377215a-d49f-44dc-a6e9-57cfe35713c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_empty_words_big_words_and_small_sentences(sentences,max_word_size=15,min_sentence_size=5):\n",
    "    for i in tqdm(range(len(sentences)), desc=\"Filtering small sentences\", total=len(sentences)):\n",
    "        sentences[i] = [word for word in sentences[i] if 0 < len(word) < max_word_size]\n",
    "        if len(sentences[i])<min_sentence_size:\n",
    "            sentences[i] = None\n",
    "    sentences = [s for s in sentences if s is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4813ca-1d0c-49be-809a-27e020a4fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sentences_to_text(sentences, filename, output_dir='sentence_texts/', max_words_per_file=10_000_000):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    base_filename = filename.replace('.csv', '')\n",
    "    skipped = 0\n",
    "    word_count = 0\n",
    "    file_index = 0\n",
    "    current_file = open(os.path.join(output_dir, f\"{base_filename}_sentences_{file_index}.txt\"), 'w', encoding='utf-8')\n",
    "    for sentence in tqdm(sentences, desc=\"Writing sentences to text files\"):\n",
    "        if sentence is None:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        if word_count + len(sentence) > max_words_per_file:\n",
    "            current_file.close()\n",
    "            file_index += 1\n",
    "            current_file = open(os.path.join(output_dir, f\"{base_filename}_sentences_{file_index}.txt\"), 'w', encoding='utf-8')\n",
    "            word_count = 0\n",
    "        line = ' '.join(sentence)\n",
    "        current_file.write(line + '\\n')\n",
    "        word_count += len(sentence)\n",
    "    current_file.close()\n",
    "    if skipped > 0:\n",
    "        print(f\"Skipped {skipped} sentences due to errors or being empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f349b12f-0d22-46fb-9c36-ff1ff7f509bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_pipeline(filename,col,max_reviews_per_file=10e7,split_to_smaller = True):\n",
    "    reviews = extract_reviews(filename,col,max_reviews_per_file)\n",
    "    lower_case_reviews(reviews)\n",
    "    replace_punctuation(reviews)\n",
    "    if split_to_smaller:\n",
    "        split_extend(reviews)\n",
    "    split_sentences_into_words(reviews)\n",
    "    replace_words_with_special_symbols(reviews)\n",
    "    replace_digit_words(reviews)\n",
    "    remove_non_alpha_numeric(reviews)\n",
    "    filter_empty_words_big_words_and_small_sentences(reviews)\n",
    "    save_sentences_to_text(reviews,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab55533-8e0d-40af-a1d3-8cbddad8e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_reviews = {\n",
    "    'wikitext_sentences.csv' : 0,\n",
    "    'book_reviews.csv': 9,\n",
    "    'food_reviews.csv': 5,\n",
    "    'hotel_reviews.csv': 2,\n",
    "    'movies_reviews.csv': 0,\n",
    "    'steam_game_reviews.csv': 0,\n",
    "    'amazon_reviews.csv': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31a35fe-5743-4087-800d-7ad5af3cc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename,review_col in csv_files_reviews.items():\n",
    "#     print(f\"Proccesing {filename}\")\n",
    "#     csv_pipeline(filename,review_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c25b3d-5a2d-4213-91fe-95657385b428",
   "metadata": {},
   "source": [
    "<h2>Generating the Word Embeddings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52547d9f-fae4-496f-a3d2-89992c3b0651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import lil_matrix,coo_matrix, save_npz,csr_matrix\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle\n",
    "\n",
    "def load_text_batches(sentences_dir='sentence_texts/', num_files=None):\n",
    "    text_files = sorted(glob.glob(f'{sentences_dir}*.txt'))\n",
    "    if num_files is None:\n",
    "        selected_files = text_files\n",
    "    else:\n",
    "        num_files = min(num_files, len(text_files))\n",
    "        selected_files = random.sample(text_files, num_files)\n",
    "    for file in tqdm(selected_files, desc=\"Processing text batches\"):\n",
    "        sentences = []\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                words = line.strip().split(' ') \n",
    "                if words:\n",
    "                    sentences.append(words)\n",
    "        yield sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf75d87-5b4a-448f-bb0c-2cf620f8ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_occurrences(sentences_dir='sentence_texts/', num_files=None):\n",
    "    word_count = defaultdict(int)\n",
    "    for sentences in load_text_batches(sentences_dir, num_files):\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                word_count[word] += 1\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f352c8c3-87c9-4171-9afb-965bfb138518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(vocabulary_size=75_000):\n",
    "    word_count_dict = count_word_occurrences()\n",
    "    print(\"Sorting counter\")\n",
    "    sorted_dict = sorted(word_count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_words = dict(sorted_dict[:vocabulary_size])\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b7ae213-0e95-4cd1-956a-202e78595de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_counts = get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7526c5da-3619-497a-8ca4-8f157360fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_counts(word_counts, filepath='word_counts.pkl'):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(word_counts, f)\n",
    "def load_word_counts(filepath='word_counts.pkl'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e02e760-4637-42ee-a427-86bab7796a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000\n"
     ]
    }
   ],
   "source": [
    "#save_word_counts(word_counts, 'word_counts.pkl')\n",
    "word_counts = load_word_counts('word_counts.pkl')\n",
    "print(len(word_counts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0386463-88e8-474b-89a4-798d612194f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(sentences, word_to_idx, vocab_size, window_size):\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    values = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        for i, target_word in enumerate(sentence):\n",
    "            if target_word not in word_to_idx:\n",
    "                continue\n",
    "            target_idx = word_to_idx[target_word]\n",
    "            start_idx = max(i - window_size, 0)\n",
    "            end_idx = min(i + window_size + 1, len(sentence))\n",
    "    \n",
    "            for j in range(start_idx, end_idx):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                context_word = sentence[j]\n",
    "                if context_word not in word_to_idx:\n",
    "                    continue\n",
    "                context_idx = word_to_idx[context_word]\n",
    "                row_indices.append(target_idx)\n",
    "                col_indices.append(context_idx)\n",
    "                values.append(1)\n",
    "    \n",
    "    return coo_matrix((values, (row_indices, col_indices)), shape=(vocab_size, vocab_size))\n",
    "\n",
    "def build_cooccurrence_matrix(vocabulary, sentences_dir='sentence_texts/', window_size=5, save_interval=10):\n",
    "    word_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "    vocab_size = len(vocabulary)\n",
    "\n",
    "    total_matrix = coo_matrix((vocab_size, vocab_size))  \n",
    "    file_count = 0\n",
    "\n",
    "    for batch_sentences in load_text_batches(sentences_dir=sentences_dir):\n",
    "        file_count += 1\n",
    "        matrix = process_batch(batch_sentences, word_to_idx, vocab_size, window_size)\n",
    "        total_matrix = total_matrix + matrix\n",
    "\n",
    "        if file_count % save_interval == 0:\n",
    "            print(f\"Saving co-occurrence matrix after processing {file_count} files...\")\n",
    "            save_npz(f'cooccurrence_matrix.npz', total_matrix.tocsr())\n",
    "\n",
    "    final_matrix = total_matrix.tocsr()\n",
    "    save_npz('cooccurrence_matrix_final.npz', final_matrix)\n",
    "    return final_matrix, word_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e530e48-776f-45d7-b2c4-1f68b9ead0e6",
   "metadata": {},
   "source": [
    "Creating the cooccurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be876413-f266-4fa2-b07a-716b7a3fff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cooccurrence_matrix, word_to_idx = build_cooccurrence_matrix(top_words, window_size=5, save_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b63fb77-7501-4540-bb84-7eace878c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.sparse import load_npz,save_npz, csr_matrix, issparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba3f3c9c-64b9-4ce0-82f9-3be0087f87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_and_dict(embeddings_matrix, word_to_index, embeddings_file, dict_file):\n",
    "    save_npz(embeddings_file, embeddings_matrix)\n",
    "    with open(dict_file, 'wb') as f:\n",
    "        pickle.dump(word_to_index, f)\n",
    "\n",
    "#save_embeddings_and_dict(cooccurrence_matrix, word_to_idx, \"cooccurrence_matrix_final.npz\", \"word_to_index.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f7f0e4e-acc5-436a-a9c1-8dc8b6ccb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_and_dicts(embeddings_file, word_to_idx_file, word_count_file):\n",
    "    embeddings_matrix = load_npz(embeddings_file)\n",
    "    with open(word_to_idx_file, 'rb') as f:\n",
    "        word_to_index = pickle.load(f)\n",
    "    with open(word_count_file, 'rb') as f:\n",
    "        word_count = pickle.load(f)\n",
    "    return embeddings_matrix, word_to_index, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c468f77-49b3-4ffd-a86b-5214c442a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_matrix, word_to_idx, word_count = load_embeddings_and_dicts(\"cooccurrence_matrix_final.npz\", \"word_to_index.pkl\",\"word_counts.pkl\")\n",
    "\n",
    "#Normalize the rows and columns of the matrix before reducing the dimensions to get better results\n",
    "\n",
    "#cooccurrence_matrix_normalized = normalize(cooccurrence_matrix, norm='l2', axis=1, copy=True)\n",
    "#cooccurrence_matrix_normalized = normalize(cooccurrence_matrix_normalized, norm='l2', axis=0,copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "161a6e58-fb77-417b-bdf2-b239809de362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_similar_words(embeddings, word_to_index, target_word, k=10):\n",
    "    target_index = word_to_index[target_word]\n",
    "    if issparse(embeddings):\n",
    "        target_embedding = embeddings[target_index].toarray().reshape(1, -1)\n",
    "    else:\n",
    "        target_embedding = embeddings[target_index].reshape(1, -1)\n",
    "    similarities = cosine_similarity(target_embedding, embeddings).flatten()\n",
    "    similar_indices = similarities.argsort()[::-1][1:k+1]\n",
    "    index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "    top_k_words = [index_to_word[i] for i in similar_indices]\n",
    "    return top_k_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac76e3f-1d1e-4874-9801-3ead59939b76",
   "metadata": {},
   "source": [
    "Reducing dimension from 75_000 to 200 in a computationally efficient way using RandomProjection and SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61f59965-d739-47af-9e72-e9cd713b3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def reduce_embeddings(cooccurrence_matrix_normalized,projection_components=5_000,pca_components=100):\n",
    "    random_projection = SparseRandomProjection(n_components=projection_components)\n",
    "    print(\"Projecting\")\n",
    "    embeddings_reduced = random_projection.fit_transform(cooccurrence_matrix_normalized)\n",
    "    print(\"Scaling\")\n",
    "    scaler = StandardScaler(with_mean=True)  \n",
    "    embeddings_reduced = scaler.fit_transform(embeddings_reduced.toarray())\n",
    "    print(\"SVD\")\n",
    "    svd = TruncatedSVD(n_components=pca_components)\n",
    "    embeddings_reduced = svd.fit_transform(embeddings_reduced)\n",
    "    return embeddings_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efa1b745-9a75-483f-9607-859730b51213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = reduce_embeddings(cooccurrence_matrix_normalized,8_000,200)\n",
    "#save_embeddings_and_dict(csr_matrix(embeddings), word_to_idx, \"embeddings_pca_200_75k_window5.npz\", \"word_to_index.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959b8f1-ddf4-4543-93d4-5b7703ce21b3",
   "metadata": {},
   "source": [
    "<h2>Testing the word embeddings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9a1ce32-0180-4454-9fcd-bd43fb0adc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_npz('embeddings_pca_200_75k_window5.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8bd76-6da6-490a-ae1e-a73abc30a3aa",
   "metadata": {},
   "source": [
    "Printing similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bed911ad-1bca-4c71-8e0a-4144d0004cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baby</th>\n",
       "      <th>boat</th>\n",
       "      <th>energy</th>\n",
       "      <th>gold</th>\n",
       "      <th>danger</th>\n",
       "      <th>phone</th>\n",
       "      <th>philosophy</th>\n",
       "      <th>drink</th>\n",
       "      <th>fight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babies</td>\n",
       "      <td>boats</td>\n",
       "      <td>energies</td>\n",
       "      <td>silver</td>\n",
       "      <td>terror</td>\n",
       "      <td>phones</td>\n",
       "      <td>philosophical</td>\n",
       "      <td>beverage</td>\n",
       "      <td>fighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>newborn</td>\n",
       "      <td>sail</td>\n",
       "      <td>generate</td>\n",
       "      <td>diamond</td>\n",
       "      <td>escape</td>\n",
       "      <td>cellphone</td>\n",
       "      <td>philosophies</td>\n",
       "      <td>drinks</td>\n",
       "      <td>enemy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>babys</td>\n",
       "      <td>ship</td>\n",
       "      <td>generating</td>\n",
       "      <td>platinum</td>\n",
       "      <td>dangers</td>\n",
       "      <td>charging</td>\n",
       "      <td>philosophers</td>\n",
       "      <td>wine</td>\n",
       "      <td>fights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toddler</td>\n",
       "      <td>sailing</td>\n",
       "      <td>renewable</td>\n",
       "      <td>turquoise</td>\n",
       "      <td>struggle</td>\n",
       "      <td>handset</td>\n",
       "      <td>ethics</td>\n",
       "      <td>cocktail</td>\n",
       "      <td>enemies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mom</td>\n",
       "      <td>ships</td>\n",
       "      <td>produce</td>\n",
       "      <td>bronze</td>\n",
       "      <td>fear</td>\n",
       "      <td>cingular</td>\n",
       "      <td>thinkers</td>\n",
       "      <td>beer</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      baby     boat      energy       gold    danger      phone  \\\n",
       "0   babies    boats    energies     silver    terror     phones   \n",
       "1  newborn     sail    generate    diamond    escape  cellphone   \n",
       "2    babys     ship  generating   platinum   dangers   charging   \n",
       "3  toddler  sailing   renewable  turquoise  struggle    handset   \n",
       "4      mom    ships     produce     bronze      fear   cingular   \n",
       "\n",
       "      philosophy     drink     fight  \n",
       "0  philosophical  beverage  fighting  \n",
       "1   philosophies    drinks     enemy  \n",
       "2   philosophers      wine    fights  \n",
       "3         ethics  cocktail   enemies  \n",
       "4       thinkers      beer      boss  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "words_to_check = ['baby', 'boat', 'energy', 'gold', 'danger','phone','philosophy','drink','fight']\n",
    "results = {}\n",
    "\n",
    "for word in words_to_check:\n",
    "    similar_words = return_most_similar_words(embeddings, word_to_idx, word, k=5)\n",
    "    results[word] = similar_words\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922cc5e-802e-4f0b-ac6a-b42d2d1b0839",
   "metadata": {},
   "source": [
    "This test consists of checking whether we can correctly classify each word in unknown_words into its correct category in the categories dictionary based on their representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53e16be1-fa5e-43db-a684-48f77c3323d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'animals': ['dog','horse','fish'],\n",
    "    'food': ['pizza','bread','tuna'],\n",
    "    'weather': ['rain','wind','humidity'],\n",
    "    'sports': ['soccer','tennis','karate'],\n",
    "    'technology': ['computer','screen','information']\n",
    "}\n",
    "\n",
    "unknown_words = [\n",
    "    # Animals (8)\n",
    "    'elephant', 'tiger', 'rabbit', 'cat', 'monkey', 'lion', 'giraffe', 'bear',\n",
    "\n",
    "    # Food (8)\n",
    "    'cheese', 'pasta', 'salad', 'burger', 'apple', 'steak', 'sushi', 'chocolate',\n",
    "\n",
    "    # Weather (8)\n",
    "    'snow', 'sun', 'storm', 'cloud', 'fog', 'lightning', 'hail', 'temperature',\n",
    "\n",
    "    # Sports (8)\n",
    "    'basketball', 'golf', 'baseball', 'boxing', 'hockey', 'hiking', 'swimming', 'cycling',\n",
    "\n",
    "    # Technology (8)\n",
    "    'internet', 'keyboard', 'software', 'algorithm', 'cable', 'machine', 'network', 'database'\n",
    "]\n",
    "\n",
    "random.shuffle(unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c428461-211f-4662-919f-2eb5ce4f403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_vector(words, embeddings, word_to_idx):\n",
    "    vectors = [embeddings[word_to_idx[w]].toarray() for w in words]\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "266a562c-1dfd-4ded-819b-599f9acbd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in unknown_words:\n",
    "    curr_word_emb = embeddings[word_to_idx[word]].toarray()\n",
    "    max_similarity = -1\n",
    "    best_bin = None\n",
    "    for category, bin_words in categories.items():\n",
    "        bin_vec = get_average_vector(bin_words, embeddings,word_to_idx)\n",
    "        similarity = cosine_similarity(curr_word_emb, bin_vec)[0][0]\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_bin = category\n",
    "    if best_bin:\n",
    "        categories[best_bin].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a28b0df-06bf-4147-ba86-7bd9199ed95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "max_len = max(len(words) for words in categories.values())\n",
    "df = pd.DataFrame({\n",
    "    category.capitalize(): categories[category] + [\"\"] * (max_len - len(categories[category]))\n",
    "    for category in categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36dcde42-b823-41c7-b1a1-194ba04f7583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animals</th>\n",
       "      <th>Food</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>pizza</td>\n",
       "      <td>rain</td>\n",
       "      <td>soccer</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horse</td>\n",
       "      <td>bread</td>\n",
       "      <td>wind</td>\n",
       "      <td>tennis</td>\n",
       "      <td>screen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fish</td>\n",
       "      <td>tuna</td>\n",
       "      <td>humidity</td>\n",
       "      <td>karate</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiger</td>\n",
       "      <td>burger</td>\n",
       "      <td>snow</td>\n",
       "      <td>golf</td>\n",
       "      <td>database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elephant</td>\n",
       "      <td>cheese</td>\n",
       "      <td>sun</td>\n",
       "      <td>basketball</td>\n",
       "      <td>keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat</td>\n",
       "      <td>sushi</td>\n",
       "      <td>temperature</td>\n",
       "      <td>hiking</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>steak</td>\n",
       "      <td>lightning</td>\n",
       "      <td>cycling</td>\n",
       "      <td>cable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>monkey</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>cloud</td>\n",
       "      <td>baseball</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bear</td>\n",
       "      <td>apple</td>\n",
       "      <td>hail</td>\n",
       "      <td>swimming</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>giraffe</td>\n",
       "      <td>salad</td>\n",
       "      <td>storm</td>\n",
       "      <td>hockey</td>\n",
       "      <td>algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lion</td>\n",
       "      <td>pasta</td>\n",
       "      <td>fog</td>\n",
       "      <td>boxing</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Animals       Food      Weather      Sports   Technology\n",
       "0        dog      pizza         rain      soccer     computer\n",
       "1      horse      bread         wind      tennis       screen\n",
       "2       fish       tuna     humidity      karate  information\n",
       "3      tiger     burger         snow        golf     database\n",
       "4   elephant     cheese          sun  basketball     keyboard\n",
       "5        cat      sushi  temperature      hiking     internet\n",
       "6     rabbit      steak    lightning     cycling        cable\n",
       "7     monkey  chocolate        cloud    baseball      network\n",
       "8       bear      apple         hail    swimming      machine\n",
       "9    giraffe      salad        storm      hockey    algorithm\n",
       "10      lion      pasta          fog      boxing     software"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889cb6-8a16-4611-839f-6040d7d138c1",
   "metadata": {},
   "source": [
    "<h3>Amazing!</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ee0ee-3055-4c3c-a231-4154b4787f7f",
   "metadata": {},
   "source": [
    "<h2>Embedding sentences and Testing it</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de3cce-7c92-4c6e-b346-59e94b223b99",
   "metadata": {},
   "source": [
    "Here, we are going to try to generate sentence embeddings from word embeddings. The task is to identify which two out of three given sentences are on the same topic, where two sentences share a topic and the third does not.\n",
    "\n",
    "I made sure that sentences in the same triplet don't share any words, which makes approaches like CountVectorizer with TF-IDF completely useless.\n",
    "\n",
    "By randomly guessing the answer, we would get 33% correct. In our test, the results were 93%, which is impressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e83c8ac-0804-49aa-8207-1ffeaf6ade80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample triplets. The rest are in the hidden cell\n",
    "triplets = [\n",
    "    (['carrots', 'are', 'rich', 'in', 'vitamin', 'a'],\n",
    "     ['broccoli', 'contains', 'lots', 'of', 'fiber'],\n",
    "     ['mountains', 'reach', 'into', 'the', 'sky']),\n",
    "\n",
    "    (['lions', 'roam', 'across', 'savannahs'],\n",
    "     ['cheetahs', 'sprint', 'after', 'prey'],\n",
    "     ['paint', 'dries', 'slowly', 'on', 'canvas']),\n",
    "\n",
    "    (['python', 'is', 'a', 'popular', 'language'],\n",
    "     ['java', 'supports', 'object', 'oriented', 'coding'],\n",
    "     ['balloons', 'float', 'during', 'parties'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4381d8db-dcb1-445f-8185-248a89f8de9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "triplets = [\n",
    "    (['carrots', 'are', 'rich', 'in', 'vitamin', 'a'],\n",
    "     ['broccoli', 'contains', 'lots', 'of', 'fiber'],\n",
    "     ['mountains', 'reach', 'into', 'the', 'sky']),\n",
    "\n",
    "    (['lions', 'roam', 'across', 'savannahs'],\n",
    "     ['cheetahs', 'sprint', 'after', 'prey'],\n",
    "     ['paint', 'dries', 'slowly', 'on', 'canvas']),\n",
    "\n",
    "    (['python', 'is', 'a', 'popular', 'language'],\n",
    "     ['java', 'supports', 'object', 'oriented', 'coding'],\n",
    "     ['balloons', 'float', 'during', 'parties']),\n",
    "\n",
    "    (['cucumbers', 'are', 'cool', 'and', 'crisp'],\n",
    "     ['zucchini', 'grows', 'in', 'warm', 'seasons'],\n",
    "     ['giraffes', 'browse', 'on', 'acacia', 'trees']),\n",
    "\n",
    "    (['basketball', 'requires', 'speed', 'with', 'agility'],\n",
    "     ['soccer', 'demands', 'endurance', 'and', 'skill'],\n",
    "     ['candles', 'melt', 'into', 'pools']),\n",
    "\n",
    "    (['trains', 'move', 'along', 'tracks'],\n",
    "     ['planes', 'fly', 'across', 'continents'],\n",
    "     ['oranges', 'are', 'juicy', 'and', 'tart']),\n",
    "\n",
    "    (['eagles', 'soar', 'above', 'valleys'],\n",
    "     ['owls', 'hunt', 'by', 'night'],\n",
    "     ['toys', 'scatter', 'across', 'the', 'floor']),\n",
    "\n",
    "    (['volcanoes', 'erupt', 'with', 'magma'],\n",
    "     ['earthquakes', 'shake', 'the', 'ground'],\n",
    "     ['pencils', 'rest', 'on', 'a', 'desk']),\n",
    "\n",
    "    (['rabbits', 'hop', 'through', 'fields'],\n",
    "     ['foxes', 'prowl', 'after', 'dusk'],\n",
    "     ['cameras', 'snap', 'bright', 'photos']),\n",
    "\n",
    "    (['roses', 'smell', 'sweet', 'in', 'bloom'],\n",
    "     ['tulips', 'sway', 'in', 'the', 'wind'],\n",
    "     ['monkeys', 'swing', 'through', 'branches']),\n",
    "\n",
    "    (['keyboards', 'have', 'many', 'buttons'],\n",
    "     ['monitors', 'display', 'high', 'resolution'],\n",
    "     ['snowflakes', 'land', 'on', 'tongues']),\n",
    "\n",
    "    (['dolphins', 'leap', 'from', 'water'],\n",
    "     ['whales', 'sing', 'beneath', 'waves'],\n",
    "     ['bookshelves', 'line', 'the', 'hallway']),\n",
    "\n",
    "    (['notebooks', 'hold', 'handwritten', 'notes'],\n",
    "     ['binders', 'organize', 'paperwork', 'easily'],\n",
    "     ['zebras', 'graze', 'on', 'plains']),\n",
    "\n",
    "    (['chairs', 'support', 'our', 'backs'],\n",
    "     ['couches', 'provide', 'comfort', 'at', 'home'],\n",
    "     ['glaciers', 'carve', 'through', 'valleys']),\n",
    "\n",
    "    (['bats', 'navigate', 'using', 'echoes'],\n",
    "     ['mice', 'scurry', 'into', 'holes'],\n",
    "     ['umbrellas', 'open', 'during', 'storms']),\n",
    "\n",
    "    (['trombones', 'blare', 'in', 'orchestras'],\n",
    "     ['violins', 'play', 'gentle', 'melodies'],\n",
    "     ['coconuts', 'fall', 'from', 'trees']),\n",
    "\n",
    "    (['beaches', 'glow', 'at', 'sunset'],\n",
    "     ['islands', 'surround', 'calm', 'lagoons'],\n",
    "     ['ladders', 'lean', 'against', 'walls']),\n",
    "\n",
    "    (['kittens', 'chase', 'fluttering', 'leaves'],\n",
    "     ['puppies', 'chew', 'on', 'rubber', 'toys'],\n",
    "     ['mirrors', 'reflect', 'our', 'faces']),\n",
    "\n",
    "    (['snowmen', 'stand', 'in', 'yards'],\n",
    "     ['sleds', 'slide', 'down', 'slopes'],\n",
    "     ['paintings', 'hang', 'on', 'galleries']),\n",
    "\n",
    "    (['cereal', 'crunches', 'in', 'milk'],\n",
    "     ['pancakes', 'soak', 'up', 'syrup'],\n",
    "     ['seagulls', 'circle', 'above', 'harbors']),\n",
    "\n",
    "    (['ice', 'melts', 'on', 'hot', 'days'],\n",
    "     ['steam', 'rises', 'from', 'cups'],\n",
    "     ['bamboo', 'bends', 'with', 'breezes']),\n",
    "\n",
    "    (['bridges', 'span', 'over', 'rivers'],\n",
    "     ['tunnels', 'run', 'under', 'cities'],\n",
    "     ['gloves', 'keep', 'hands', 'warm']),\n",
    "\n",
    "    (['apples', 'grow', 'on', 'orchards'],\n",
    "     ['pears', 'ripen', 'in', 'autumn'],\n",
    "     ['drums', 'beat', 'rhythms', 'loudly']),\n",
    "\n",
    "    (['clouds', 'float', 'in', 'skies'],\n",
    "     ['storms', 'gather', 'during', 'spring'],\n",
    "     ['tickets', 'grant', 'entry', 'to', 'shows']),\n",
    "\n",
    "    (['elevators', 'ascend', 'at', 'towers'],\n",
    "     ['escalators', 'glide', 'between', 'floors'],\n",
    "     ['foxglove', 'blooms', 'in', 'gardens']),\n",
    "\n",
    "    (['hammers', 'strike', 'nails'],\n",
    "     ['saws', 'cut', 'through', 'planks'],\n",
    "     ['penguins', 'waddle', 'on', 'icebergs']),\n",
    "\n",
    "    (['trumpets', 'blow', 'brassy', 'sounds'],\n",
    "     ['flutes', 'whistle', 'soft', 'notes'],\n",
    "     ['meadows', 'stretch', 'for', 'miles']),\n",
    "\n",
    "    (['pencils', 'write', 'on', 'paper'],\n",
    "     ['pens', 'leave', 'permanent', 'ink'],\n",
    "     ['craters', 'dot', 'the', 'moon']),\n",
    "\n",
    "    (['leopards', 'stalk', 'quietly'],\n",
    "     ['hyenas', 'laugh', 'in', 'packs'],\n",
    "     ['sandals', 'protect', 'feet', 'on', 'paths']),\n",
    "\n",
    "    (['surfboards', 'glide', 'over', 'waves'],\n",
    "     ['kayaks', 'drift', 'down', 'rivers'],\n",
    "     ['magnets', 'stick', 'to', 'metal']),\n",
    "\n",
    "    (['deserts', 'bake', 'beneath', 'suns'],\n",
    "     ['cacti', 'store', 'water'],\n",
    "     ['suits', 'hang', 'in', 'closets']),\n",
    "\n",
    "    (['computers', 'run', 'on', 'electricity'],\n",
    "     ['routers', 'manage', 'network', 'traffic'],\n",
    "     ['candies', 'come', 'in', 'wrappers']),\n",
    "\n",
    "    (['spoons', 'hold', 'liquid', 'foods'],\n",
    "     ['forks', 'pierce', 'vegetables'],\n",
    "     ['alligators', 'swim', 'in', 'marshes']),\n",
    "\n",
    "    (['guitars', 'strum', 'melodic', 'chords'],\n",
    "     ['drummers', 'keep', 'time', 'with', 'beats'],\n",
    "     ['kites', 'fly', 'on', 'windy', 'days']),\n",
    "\n",
    "    (['planets', 'orbit', 'distant', 'stars'],\n",
    "     ['asteroids', 'travel', 'through', 'space'],\n",
    "     ['suitcases', 'carry', 'clothes', 'for', 'trips']),\n",
    "\n",
    "    (['honeybees', 'collect', 'nectar'],\n",
    "     ['wasps', 'build', 'paper', 'nests'],\n",
    "     ['scissors', 'cut', 'through', 'fabric']),\n",
    "\n",
    "    (['crayons', 'color', 'on', 'pages'],\n",
    "     ['markers', 'leave', 'bold', 'lines'],\n",
    "     ['fireworks', 'explode', 'during', 'holidays']),\n",
    "\n",
    "    (['sunscreen', 'protects', 'skin'],\n",
    "     ['hats', 'shade', 'your', 'face'],\n",
    "     ['statues', 'stand', 'in', 'parks']),\n",
    "\n",
    "    (['beavers', 'build', 'dams'],\n",
    "     ['otters', 'float', 'on', 'backs'],\n",
    "     ['backpacks', 'carry', 'books']),\n",
    "\n",
    "    (['watches', 'track', 'time'],\n",
    "     ['alarms', 'wake', 'people', 'early'],\n",
    "     ['bubbles', 'rise', 'in', 'water']),\n",
    "\n",
    "    (['jeans', 'fit', 'snugly'],\n",
    "     ['jackets', 'keep', 'you', 'warm'],\n",
    "     ['lanterns', 'glow', 'in', 'darkness']),\n",
    "\n",
    "    (['raindrops', 'tap', 'on', 'windows'],\n",
    "     ['breeze', 'enters', 'the','door'],\n",
    "     ['mirrors', 'shatter', 'when', 'punched']),\n",
    "\n",
    "    (['hedgehogs', 'curl', 'into', 'balls'],\n",
    "     ['badgers', 'dig', 'deep', 'holes'],\n",
    "     ['rulers', 'measure', 'straight', 'lines']),\n",
    "\n",
    "    (['windmills', 'spin', 'in', 'breezes'],\n",
    "     ['solar', 'panels', 'absorb', 'sunlight'],\n",
    "     ['picnics', 'happen', 'on', 'lawns']),\n",
    "\n",
    "    (['camels', 'endure', 'heat'],\n",
    "     ['lizards', 'scuttle', 'on', 'rocks'],\n",
    "     ['couches', 'face', 'televisions']),\n",
    "\n",
    "    (['schoolbags', 'hold', 'supplies'],\n",
    "     ['pencilcases', 'store', 'erasers'],\n",
    "     ['staircases', 'lead', 'to', 'attics']),\n",
    "\n",
    "    (['penguins', 'dive', 'under', 'ice'],\n",
    "     ['seals', 'slide', 'on', 'bellies'],\n",
    "     ['statements', 'end', 'with', 'periods']),\n",
    "\n",
    "    (['lava', 'flows', 'from', 'craters'],\n",
    "     ['ash', 'clouds', 'fill', 'the', 'sky'],\n",
    "     ['baskets', 'carry', 'fruits']),\n",
    "\n",
    "    (['fireflies', 'blink', 'in', 'meadows'],\n",
    "     ['crickets', 'chirp', 'over', 'grass'],\n",
    "     ['pillows', 'soften', 'your', 'head']),\n",
    "    (\n",
    "        ['we', 'toured', 'city', 'on', 'a', 'bus', 'visited', 'the'],\n",
    "        ['she', 'booked', 'her', 'flights', 'to', 'new', 'york', 'for', 'vacation'],\n",
    "        ['he', 'fixed', 'leak', 'in', 'roof', 'of', 'house']\n",
    "    ),\n",
    "        (['brightly', 'orange', 'carrots', 'are', 'very', 'rich', 'in', 'essential', 'vitamin', 'a'],\n",
    "     ['green', 'broccoli', 'contains', 'a', 'significant', 'amount', 'of', 'dietary', 'fiber'],\n",
    "     ['tall', 'mountains', 'majestically', 'reach', 'far', 'into', 'the', 'blue', 'sky']),\n",
    "\n",
    "    (['ferocious', 'lions', 'often', 'roam', 'freely', 'across', 'vast', 'African', 'savannahs'],\n",
    "     ['swift', 'cheetahs', 'can', 'sprint', 'rapidly', 'after', 'their', 'fleeting', 'prey'],\n",
    "     ['wet', 'paint', 'typically', 'dries', 'quite', 'slowly', 'on', 'a', 'stretched', 'canvas']),\n",
    "\n",
    "    (['popular', 'python', 'is', 'considered', 'a', 'versatile', 'programming', 'language'],\n",
    "     ['robust', 'java', 'effectively', 'supports', 'complex', 'object', 'oriented', 'software', 'coding'],\n",
    "     ['colorful', 'balloons', 'gently', 'float', 'upward', 'during', 'festive', 'outdoor', 'parties']),\n",
    "\n",
    "    (['cool', 'and', 'crisp', 'cucumbers', 'are', 'refreshing', 'summer', 'vegetables'],\n",
    "     ['green', 'zucchini', 'usually', 'grows', 'well', 'in', 'long', 'warm', 'summer', 'seasons'],\n",
    "     ['graceful', 'giraffes', 'frequently', 'browse', 'peacefully', 'on', 'tall', 'acacia', 'trees']),\n",
    "\n",
    "    (['fast', 'basketball', 'often', 'requires', 'both', 'great', 'speed', 'along', 'with', 'excellent', 'agility'],\n",
    "     ['competitive', 'soccer', 'typically', 'demands', 'significant', 'endurance', 'plus', 'considerable', 'foot', 'skill'],\n",
    "     ['lit', 'candles', 'slowly', 'melt', 'down', 'into', 'small', 'liquid', 'wax', 'pools']),\n",
    "\n",
    "    (['long', 'trains', 'frequently', 'move', 'steadily', 'along', 'steel', 'tracks'],\n",
    "     ['large', 'planes', 'can', 'fly', 'swiftly', 'across', 'distant', 'continents'],\n",
    "     ['ripe', 'oranges', 'are', 'generally', 'quite', 'juicy', 'and', 'pleasantly', 'tart']),\n",
    "\n",
    "    (['majestic', 'eagles', 'often', 'soar', 'gracefully', 'high', 'above', 'wide', 'valleys'],\n",
    "     ['nocturnal', 'owls', 'primarily', 'hunt', 'actively', 'by', 'the', 'dark', 'night'],\n",
    "     ['various', 'toys', 'tend', 'to', 'scatter', 'randomly', 'across', 'the', 'untidy', 'floor']),\n",
    "\n",
    "    (['active', 'volcanoes', 'can', 'violently', 'erupt', 'suddenly', 'with', 'molten', 'hot', 'magma'],\n",
    "     ['powerful', 'earthquakes', 'can', 'violently', 'shake', 'the', 'solid', 'ground', 'beneath'],\n",
    "     ['wooden', 'pencils', 'usually', 'rest', 'motionless', 'on', 'a', 'cluttered', 'desk']),\n",
    "\n",
    "    (['quick', 'rabbits', 'often', 'hop', 'merrily', 'through', 'green', 'fields'],\n",
    "     ['stealthy', 'foxes', 'typically', 'prowl', 'quietly', 'after', 'the', 'late', 'dusk'],\n",
    "     ['modern', 'cameras', 'can', 'easily', 'snap', 'clear', 'bright', 'digital', 'photos']),\n",
    "\n",
    "    (['fragrant', 'roses', 'often', 'smell', 'wonderfully', 'sweet', 'when', 'in', 'full', 'bloom'],\n",
    "     ['colorful', 'tulips', 'gently', 'sway', 'back', 'and', 'forth', 'in', 'the', 'breeze', 'wind'],\n",
    "     ['agile', 'monkeys', 'frequently', 'swing', 'effortlessly', 'through', 'tall', 'forest', 'branches']),\n",
    "\n",
    "    (['modern', 'keyboards', 'typically', 'have', 'numerous', 'small', 'plastic', 'buttons'],\n",
    "     ['large', 'monitors', 'clearly', 'display', 'high', 'screen', 'resolution', 'images'],\n",
    "     ['delicate', 'snowflakes', 'gently', 'land', 'softly', 'on', 'outstretched', 'tongues']),\n",
    "\n",
    "    (['playful', 'dolphins', 'often', 'leap', 'joyfully', 'high', 'from', 'the', 'ocean', 'water'],\n",
    "     ['large', 'whales', 'sometimes', 'sing', 'melodically', 'deep', 'beneath', 'the', 'ocean', 'waves'],\n",
    "     ['tall', 'bookshelves', 'usually', 'line', 'the', 'long', 'narrow', 'hallway']),\n",
    "\n",
    "    (['organized', 'notebooks', 'frequently', 'hold', 'many', 'handwritten', 'personal', 'notes'],\n",
    "     ['sturdy', 'binders', 'help', 'organize', 'loose', 'paperwork', 'quite', 'easily', 'by', 'topic'],\n",
    "     ['wild', 'zebras', 'often', 'graze', 'peacefully', 'on', 'the', 'vast', 'African', 'plains']),\n",
    "\n",
    "    (['comfortable', 'chairs', 'are', 'designed', 'to', 'support', 'our', 'tired', 'backs'],\n",
    "     ['soft', 'couches', 'usually', 'provide', 'great', 'comfort', 'to', 'people', 'at', 'home'],\n",
    "     ['massive', 'glaciers', 'slowly', 'carve', 'deeply', 'through', 'mountainous', 'valleys']),\n",
    "\n",
    "    (['nocturnal', 'bats', 'skillfully', 'navigate', 'effectively', 'using', 'high-frequency', 'echoes'],\n",
    "     ['tiny', 'mice', 'often', 'scurry', 'quickly', 'into', 'small', 'dark', 'holes'],\n",
    "     ['large', 'umbrellas', 'typically', 'open', 'wide', 'during', 'heavy', 'rain', 'storms']),\n",
    "\n",
    "    (['loud', 'trombones', 'can', 'blare', 'powerful', 'sounds', 'within', 'orchestras'],\n",
    "     ['melodic', 'violins', 'beautifully', 'play', 'soft', 'and', 'gentle', 'musical', 'melodies'],\n",
    "     ['ripe', 'coconuts', 'can', 'suddenly', 'fall', 'down', 'from', 'tall', 'palm', 'trees']),\n",
    "\n",
    "    (['sandy', 'beaches', 'often', 'glow', 'warmly', 'at', 'the', 'beautiful', 'sunset'],\n",
    "     ['tropical', 'islands', 'typically', 'surround', 'calm', 'clear', 'blue', 'lagoons'],\n",
    "     ['tall', 'ladders', 'usually', 'lean', 'precariously', 'against', 'exterior', 'walls']),\n",
    "\n",
    "    (['playful', 'kittens', 'often', 'chase', 'quickly', 'fluttering', 'colorful', 'leaves'],\n",
    "     ['small', 'puppies', 'frequently', 'chew', 'happily', 'on', 'soft', 'rubber', 'toys'],\n",
    "     ['shiny', 'mirrors', 'clearly', 'reflect', 'our', 'own', 'unique', 'faces']),\n",
    "\n",
    "    (['large', 'snowmen', 'often', 'stand', 'still', 'in', 'snow-covered', 'yards'],\n",
    "     ['fast', 'sleds', 'quickly', 'slide', 'rapidly', 'down', 'icy', 'slopes'],\n",
    "     ['framed', 'paintings', 'usually', 'hang', 'decoratively', 'on', 'art', 'galleries']),\n",
    "\n",
    "    (['crispy', 'cereal', 'often', 'crunches', 'noisily', 'in', 'cold', 'white', 'milk'],\n",
    "     ['fluffy', 'pancakes', 'readily', 'soak', 'completely', 'up', 'sweet', 'maple', 'syrup'],\n",
    "     ['graceful', 'seagulls', 'frequently', 'circle', 'lazily', 'high', 'above', 'busy', 'harbors']),\n",
    "\n",
    "    (['clear', 'ice', 'quickly', 'melts', 'away', 'on', 'very', 'hot', 'summer', 'days'],\n",
    "     ['hot', 'steam', 'visibly', 'rises', 'upward', 'from', 'warm', 'coffee', 'cups'],\n",
    "     ['tall', 'bamboo', 'often', 'bends', 'gently', 'back', 'and', 'forth', 'with', 'light', 'breezes']),\n",
    "\n",
    "    (['sturdy', 'bridges', 'typically', 'span', 'widely', 'over', 'flowing', 'rivers'],\n",
    "     ['dark', 'tunnels', 'usually', 'run', 'deeply', 'under', 'large', 'cities'],\n",
    "     ['warm', 'gloves', 'effectively', 'keep', 'our', 'hands', 'protected', 'and', 'warm']),\n",
    "\n",
    "    (['red', 'apples', 'commonly', 'grow', 'abundantly', 'on', 'fruitful', 'orchards'],\n",
    "     ['ripe', 'pears', 'typically', 'ripen', 'slowly', 'in', 'the', 'autumn', 'season'],\n",
    "     ['loud', 'drums', 'often', 'beat', 'strong', 'rhythms', 'very', 'loudly']),\n",
    "\n",
    "    (['white', 'clouds', 'frequently', 'float', 'lazily', 'high', 'in', 'the', 'blue', 'skies'],\n",
    "     ['severe', 'storms', 'often', 'gather', 'quickly', 'during', 'the', 'springtime', 'season'],\n",
    "     ['paper', 'tickets', 'usually', 'grant', 'easy', 'entry', 'to', 'various', 'shows']),\n",
    "\n",
    "    (['fast', 'elevators', 'quickly', 'ascend', 'smoothly', 'at', 'tall', 'city', 'towers'],\n",
    "     ['modern', 'escalators', 'gently', 'glide', 'effortlessly', 'between', 'different', 'floors'],\n",
    "     ['purple', 'foxglove', 'beautifully', 'blooms', 'vibrantly', 'in', 'well-tended', 'gardens']),\n",
    "\n",
    "    (['heavy', 'hammers', 'forcefully', 'strike', 'metal', 'nails'],\n",
    "     ['sharp', 'saws', 'efficiently', 'cut', 'cleanly', 'through', 'wooden', 'planks'],\n",
    "     ['flightless', 'penguins', 'often', 'waddle', 'awkwardly', 'on', 'slippery', 'icebergs']),\n",
    "\n",
    "    (['loud', 'trumpets', 'can', 'blow', 'strong', 'brassy', 'musical', 'sounds'],\n",
    "     ['high', 'flutes', 'often', 'whistle', 'soft', 'and', 'gentle', 'high', 'notes'],\n",
    "     ['green', 'meadows', 'typically', 'stretch', 'outward', 'for', 'many', 'long', 'miles']),\n",
    "\n",
    "    (['wooden', 'pencils', 'are', 'used', 'to', 'write', 'clearly', 'on', 'white', 'paper'],\n",
    "     ['smooth', 'pens', 'typically', 'leave', 'permanent', 'dark', 'ink', 'marks'],\n",
    "     ['numerous', 'craters', 'distinctly', 'dot', 'the', 'barren', 'surface', 'of', 'the', 'moon']),\n",
    "\n",
    "    (['stealthy', 'leopards', 'often', 'stalk', 'their', 'prey', 'very', 'quietly'],\n",
    "     ['vocal', 'hyenas', 'frequently', 'laugh', 'loudly', 'in', 'large', 'social', 'packs'],\n",
    "     ['simple', 'sandals', 'help', 'protect', 'bare', 'feet', 'while', 'on', 'sandy', 'paths']),\n",
    "\n",
    "    (['fast', 'surfboards', 'skillfully', 'glide', 'smoothly', 'over', 'ocean', 'waves'],\n",
    "     ['small', 'kayaks', 'often', 'drift', 'gently', 'down', 'winding', 'rivers'],\n",
    "     ['powerful', 'magnets', 'strongly', 'stick', 'firmly', 'to', 'ferrous', 'metal', 'surfaces']),\n",
    "\n",
    "    (['arid', 'deserts', 'often', 'bake', 'intensely', 'beneath', 'the', 'hot', 'suns'],\n",
    "     ['tough', 'cacti', 'efficiently', 'store', 'precious', 'water', 'inside'],\n",
    "     ['formal', 'suits', 'usually', 'hang', 'neatly', 'in', 'spacious', 'closets']),\n",
    "\n",
    "    (['modern', 'computers', 'typically', 'run', 'efficiently', 'on', 'electrical', 'electricity'],\n",
    "     ['network', 'routers', 'actively', 'manage', 'complex', 'internet', 'traffic'],\n",
    "     ['sweet', 'candies', 'usually', 'come', 'individually', 'in', 'colorful', 'wrappers']),\n",
    "\n",
    "    (['metal', 'spoons', 'are', 'designed', 'to', 'hold', 'liquid', 'hot', 'foods'],\n",
    "     ['sharp', 'forks', 'are', 'used', 'to', 'pierce', 'various', 'cooked', 'vegetables'],\n",
    "     ['large', 'alligators', 'often', 'swim', 'slowly', 'in', 'swampy', 'marshes']),\n",
    "\n",
    "    (['acoustic', 'guitars', 'often', 'strum', 'beautiful', 'melodic', 'musical', 'chords'],\n",
    "     ['talented', 'drummers', 'skillfully', 'keep', 'precise', 'time', 'with', 'strong', 'beats'],\n",
    "     ['colorful', 'kites', 'frequently', 'fly', 'high', 'on', 'breezy', 'windy', 'days']),\n",
    "\n",
    "    (['distant', 'planets', 'continuously', 'orbit', 'faraway', 'bright', 'stars'],\n",
    "     ['small', 'asteroids', 'constantly', 'travel', 'rapidly', 'through', 'outer', 'space'],\n",
    "     ['packed', 'suitcases', 'are', 'used', 'to', 'carry', 'personal', 'clothes', 'for', 'trips']),\n",
    "\n",
    "    (['busy', 'honeybees', 'actively', 'collect', 'sweet', 'flower', 'nectar'],\n",
    "     ['industrious', 'wasps', 'often', 'build', 'intricate', 'paper', 'nests'],\n",
    "     ['sharp', 'scissors', 'are', 'used', 'to', 'cut', 'cleanly', 'through', 'fabric']),\n",
    "\n",
    "    (['bright', 'crayons', 'are', 'used', 'to', 'color', 'vibrantly', 'on', 'paper', 'pages'],\n",
    "     ['bold', 'markers', 'typically', 'leave', 'distinct', 'dark', 'lines', 'easily'],\n",
    "     ['loud', 'fireworks', 'spectacularly', 'explode', 'noisily', 'during', 'special', 'holidays']),\n",
    "\n",
    "    (['effective', 'sunscreen', 'helps', 'protects', 'sensitive', 'skin', 'from', 'sun'],\n",
    "     ['wide', 'hats', 'effectively', 'shade', 'your', 'delicate', 'face', 'from', 'light'],\n",
    "     ['stone', 'statues', 'usually', 'stand', 'motionless', 'in', 'public', 'parks']),\n",
    "\n",
    "    (['busy', 'beavers', 'actively', 'build', 'sturdy', 'wooden', 'dams'],\n",
    "     ['aquatic', 'otters', 'often', 'float', 'lazily', 'on', 'their', 'backs', 'in', 'water'],\n",
    "     ['large', 'backpacks', 'are', 'designed', 'to', 'carry', 'heavy', 'school', 'books']),\n",
    "\n",
    "    (['accurate', 'watches', 'are', 'designed', 'to', 'track', 'precise', 'time'],\n",
    "     ['loud', 'alarms', 'are', 'set', 'to', 'wake', 'sleeping', 'people', 'quite', 'early'],\n",
    "     ['clear', 'bubbles', 'often', 'rise', 'slowly', 'in', 'clear', 'water']),\n",
    "\n",
    "    (['comfortable', 'jeans', 'usually', 'fit', 'quite', 'snugly', 'on', 'legs'],\n",
    "     ['warm', 'jackets', 'are', 'worn', 'to', 'keep', 'you', 'comfortably', 'warm'],\n",
    "     ['bright', 'lanterns', 'typically', 'glow', 'softly', 'in', 'total', 'darkness']),\n",
    "\n",
    "    (['heavy', 'raindrops', 'often', 'tap', 'gently', 'on', 'glass', 'windows'],\n",
    "     ['loud', 'thunder', 'frequently', 'rumbles', 'deeply', 'overhead', 'in', 'sky'],\n",
    "     ['fragile', 'mirrors', 'can', 'easily', 'shatter', 'into', 'pieces', 'when', 'dropped']),\n",
    "\n",
    "    (['shy', 'hedgehogs', 'quickly', 'curl', 'themselves', 'into', 'tight', 'balls'],\n",
    "     ['strong', 'badgers', 'actively', 'dig', 'deep', 'underground', 'holes'],\n",
    "     ['straight', 'rulers', 'are', 'used', 'to', 'measure', 'accurate', 'straight', 'lines']),\n",
    "    \n",
    "    (['efficient', 'solar', 'panels', 'effectively', 'absorb', 'bright', 'sunlight'],\n",
    "     ['strong', 'windmills', 'steadily', 'spin', 'around', 'in', 'light', 'breezes'],\n",
    "     ['outdoor', 'picnics', 'frequently', 'happen', 'happily', 'on', 'green', 'lawns'],\n",
    "     ),\n",
    "\n",
    "    (['sturdy', 'camels', 'can', 'endure', 'extreme', 'heat', 'well'],\n",
    "     ['small', 'lizards', 'quickly', 'scuttle', 'rapidly', 'on', 'hot', 'rocks'],\n",
    "     ['soft', 'couches', 'are', 'placed', 'to', 'face', 'large', 'televisions']),\n",
    "\n",
    "    (['heavy', 'schoolbags', 'are', 'designed', 'to', 'hold', 'many', 'supplies'],\n",
    "     ['small', 'pencilcases', 'are', 'used', 'to', 'store', 'small', 'erasers'],\n",
    "     ['long', 'staircases', 'typically', 'lead', 'upward', 'to', 'dark', 'attics']),\n",
    "\n",
    "    (['aquatic', 'penguins', 'often', 'dive', 'deeply', 'under', 'thick', 'ice'],\n",
    "     ['slippery', 'seals', 'frequently', 'slide', 'smoothly', 'on', 'their', 'bellies'],\n",
    "     ['clear', 'statements', 'always', 'end', 'correctly', 'with', 'full', 'periods']),\n",
    "\n",
    "    (['molten', 'lava', 'violently', 'flows', 'freely', 'from', 'volcanic', 'craters'],\n",
    "     ['dense', 'ash', 'clouds', 'rapidly', 'fill', 'the', 'dark', 'sky', 'above'],\n",
    "     ['woven', 'baskets', 'are', 'used', 'to', 'carry', 'fresh', 'fruits']),\n",
    "\n",
    "    (['glowing', 'fireflies', 'often', 'blink', 'brightly', 'in', 'dark', 'meadows'],\n",
    "     ['noisy', 'crickets', 'frequently', 'chirp', 'loudly', 'over', 'green', 'grass'],\n",
    "     ['soft', 'pillows', 'are', 'designed', 'to', 'soften', 'your', 'tired', 'head']),\n",
    "     (\n",
    "    ['we', 'toured', 'the', 'historic', 'city', 'on', 'a', 'bus', 'and', 'visited', 'the'],\n",
    "    ['she', 'booked', 'her', 'round-trip', 'flights', 'to', 'new', 'york', 'city', 'for', 'her', 'summer', 'vacation'],\n",
    "    ['he', 'fixed', 'the', 'leaking', 'roof', 'of', 'his', 'old', 'house', 'himself']\n",
    "     ),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2d15df68-8a7f-4b61-837a-3de65a33eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(sentence, word_to_index, embeddings, word_count,a=1e-4):\n",
    "    vecs = []\n",
    "    total_count = sum(word_count.values())\n",
    "\n",
    "    for word in sentence:\n",
    "        idx = word_to_index.get(word)\n",
    "        if idx is not None:\n",
    "            vec = embeddings[idx]\n",
    "            if hasattr(vec, \"toarray\"): \n",
    "                vec = vec.toarray().ravel()\n",
    "\n",
    "            count = word_count.get(word, 1)\n",
    "            prob = count / total_count\n",
    "            weight = a / (a + prob)\n",
    "\n",
    "            vecs.append(vec * weight)\n",
    "\n",
    "    if not vecs:\n",
    "        return np.zeros(embeddings.shape[1])\n",
    "\n",
    "    vecs = np.stack(vecs)\n",
    "    sent_vec = np.sum(vecs, axis=0)\n",
    "    norm = np.linalg.norm(sent_vec)\n",
    "    return sent_vec / norm if norm else sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4240f632-6507-4875-be24-2dfb2e8a3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_pair_with_embeddings(s1, s2, s3, word_to_index, embeddings, word_count,a=1e-4):\n",
    "    v1 = embed_sentence(s1, word_to_index, embeddings, word_count,a)\n",
    "    v2 = embed_sentence(s2, word_to_index, embeddings, word_count,a)\n",
    "    v3 = embed_sentence(s3, word_to_index, embeddings, word_count,a)\n",
    "    \n",
    "    similarity_12 = np.dot(v1, v2)\n",
    "    similarity_13 = np.dot(v1, v3)\n",
    "    similarity_23 = np.dot(v2, v3)\n",
    "\n",
    "    scores = [similarity_12, similarity_13, similarity_23]\n",
    "    return np.argmax(scores), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "a843fa18-dea9-46c1-9682-769d3799de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embeddings(embeddings,word_to_idx,a=1e-4):\n",
    "    correct = 0\n",
    "    for i, (s1, s2, s3) in enumerate(triplets):\n",
    "        idx, _ = most_similar_pair_with_embeddings(s1, s2, s3, word_to_idx, embeddings,word_count,a)\n",
    "        is_correct = idx == 0  \n",
    "        correct += is_correct\n",
    "    print(f\"Accuracy: {correct}/{len(triplets)} correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5bdfe53e-cf86-4273-832d-b40bea68231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93/100 correct\n"
     ]
    }
   ],
   "source": [
    "embeddings = load_npz('embeddings_pca_200_75k_window5.npz')\n",
    "test_embeddings(embeddings,word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "989e61fb-bfe1-4a80-9554-1385c6f3b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews(filename,review_col,max_reviews_per_file):\n",
    "    reviews = []\n",
    "    try:\n",
    "        with open(filename, 'r', encoding=\"ISO-8859-1\") as file:\n",
    "            total_reviews = sum(1 for _ in file)\n",
    "            print(f\"{filename} has {total_reviews - 1} reviews\")\n",
    "            file.seek(0)\n",
    "            my_reader = csv.reader(file, delimiter=',')\n",
    "            next(my_reader, None)\n",
    "            for i, row in enumerate(my_reader):\n",
    "                if i >= max_reviews_per_file:\n",
    "                    break\n",
    "                reviews.append(row[review_col])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "595a6d56-7370-4c9d-892c-6f93b33a975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_pipeline(filename,col,max_reviews_per_file=10e7):\n",
    "    clean_reviews = extract_reviews(filename,col,max_reviews_per_file)\n",
    "    original_reviews = [rev for rev in clean_reviews]\n",
    "    lower_case_reviews(clean_reviews)\n",
    "    replace_punctuation(clean_reviews)\n",
    "    split_sentences_into_words(clean_reviews)\n",
    "    replace_words_with_special_symbols(clean_reviews)\n",
    "    replace_digit_words(clean_reviews)\n",
    "    remove_non_alpha_numeric(clean_reviews)\n",
    "    return clean_reviews,original_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e9d62-f3e3-49e9-9fb7-91fd82b621e5",
   "metadata": {},
   "source": [
    "Loading reviews of single recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "4139a2d1-9cca-4c76-90d1-18d7506b016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe_reviews.csv has 2325 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lowercasing: 100%|████████████████████████████████████████████████████████████| 2182/2182 [00:00<00:00, 2182158.16it/s]\n",
      "Cleaning reviews: 100%|████████████████████████████████████████████████████████| 2182/2182 [00:00<00:00, 285179.21it/s]\n",
      "Splitting sentences into words: 100%|██████████████████████████████████████████| 2182/2182 [00:00<00:00, 411250.62it/s]\n",
      "Replacing special symbol words: 100%|███████████████████████████████████████████| 2182/2182 [00:00<00:00, 78850.76it/s]\n",
      "Replacing digit words: 100%|████████████████████████████████████████████████████| 2182/2182 [00:00<00:00, 35925.02it/s]\n",
      "Removing None values: 100%|████████████████████████████████████████████████████████████████| 2182/2182 [00:00<?, ?it/s]\n",
      "Removing non-alphanumeric words: 100%|██████████████████████████████████████████| 2182/2182 [00:00<00:00, 37697.34it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_reviews,original_reviews = csv_pipeline('recipe_reviews.csv',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "f2e32132-2fe5-45a1-8338-2358b3648294",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_embeddings = np.array([embed_sentence(rev, word_to_idx, embeddings, word_count) for rev in clean_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "a8d9f194-c7d0-4320-a67d-1b052ea0eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "b64594aa-47ea-42af-b365-7fdeb496fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(embeddings,'toarray'):\n",
    "    embeddings = embeddings.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "4b0f8ffd-3a01-44e3-bdb2-3d17468b5dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 48.35%\n",
      "Label 1: 12.51%\n",
      "Label 2: 29.01%\n",
      "Label 3: 10.13%\n"
     ]
    }
   ],
   "source": [
    "agglo = AgglomerativeClustering(n_clusters=4)\n",
    "agglo.fit(reviews_embeddings)\n",
    "labels = agglo.labels_\n",
    "values, value_counts = np.unique(labels, return_counts=True)\n",
    "for label, count in zip(values, value_counts):\n",
    "    print(f'Label {label}: {count * 100 / len(reviews_embeddings):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "0c442780-2162-4cb5-9e14-298356579020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_reviews_to_computed_centroids(reviews, review_embeddings, labels, top_k=3):\n",
    "    closest_reviews_per_cluster = []\n",
    "    unique_labels = np.unique(labels)\n",
    "    for label in unique_labels:\n",
    "        cluster_reviews_idx = np.where(labels == label)[0]\n",
    "        cluster_embeddings = review_embeddings[cluster_reviews_idx]\n",
    "        centroid = np.mean(cluster_embeddings, axis=0)\n",
    "        distances = np.sum((cluster_embeddings - centroid.reshape(1, -1))**2, axis=1)\n",
    "        top_indices = np.argsort(distances)[:top_k]\n",
    "        top_reviews = [reviews[cluster_reviews_idx[idx]] for idx in top_indices]\n",
    "        closest_reviews_per_cluster.append(top_reviews)\n",
    "    return closest_reviews_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "64040272-0ea5-42d4-9f3c-c50d9cda41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_reviews = find_closest_reviews_to_computed_centroids(original_reviews, reviews_embeddings, labels, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "70ad499d-3833-4fb8-9c16-af71b659e59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 1:\n",
      "\n",
      "-  Im only 15 and this is my second time making banana bread. The first time i used a different recipe and it came out so bad, but i found this recipe and it came out delicious. The perfect recipe for banana bread, im not that great at baking but this is by far the best.\n",
      "\n",
      "-  First time I baked banana bread and it turned out perfectly! I used only 1/2 cup of sugar and 4 bananas. Super moist, just the right amount of sweetness for me. Thank you for the recipe!\n",
      "\n",
      "-  This was an easy banana bread. I chose to use 4 bananas. My fiance and I both agree that this made it too moist for our liking. The bread fell apart. I also added chocolate chips. Looking forward to trying this recipe with 3 bananas and maybe with some cinnamon as another reviewer said. This recipe fit perfectly into my loaf pan, it did not overflow. It took me an extra 15 minutes (probably due to extra moistness with the 4th banana) to cook versus the time listed. I cooked it on on the middle shelf of my gas oven.\n",
      "\n",
      "-  This is by far the best banana bread recipe I've ever used, and I've used many. And yes, adding that extra banana puts it over the top!\n",
      "\n",
      "-  Great and easy recipe. Followed recipe ingredients but doubled it. Made half into muffins and the other half into the bread adding chocolate chips and almond slices. My family ate the whole thing before I could get a picture. Perfect balance btw moist and light. Definite keeper, my new go to banana bread recipe.\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "\n",
      "-  Way too much batter for one loaf pan and not enough for two. Took almost 90 minutes for one loaf to bake and it burned on the outside. Not even sure it is cooked on the inside. Not doing this again, even if it tastes good.\n",
      "\n",
      "-  I would love to rate this recipe as high as the others and I&#039;ve tried it twice.  It takes much, much, much, much, much, much (you get the point!) longer than 60 minutes to cook.  The middle never seems to cook beyond batter.  I&#039;m using a loaf pan as directed, but not having any luck with getting the middle to turn into a bread, instead of a liquid.  I&#039;ll look for a different recipe.\n",
      "\n",
      "-  I&#039;m not really sure what happened here.  I made exactly according to the directions.  When I went to take the loaf out of the pan, all the liquid poured out through the top of the bread.  I tried to put it back in the oven and cooked it for a total of about an hour and 45 minutes and it still wasn&#039;t done.  Had to toss it.  I&#039;m not sure if it was the glass loaf pan.?.?  I can&#039;t figure out why it didn&#039;t work,\n",
      "\n",
      "-  The recipe is great except for the cook time. Don't cook this recipe for 55 minutes. You will have burnt bread. I won't be baking this recipe for that long of a time again. It probably should be baked for about 25-30 minutes.\n",
      "\n",
      "-  I rated this 3 stars for the baking instructions . It does not say how many loaf pans nor the size of the pans.&lt;br/&gt;Do Not Bake this for 60 minutes. If you use dark colored loaf pans reduce heat to 325 degrees. Keep a close eye I recommend starting @30 minutes baking time and go from there.&lt;br/&gt;This recipe was moist. Folding in your flour will keep the bread tender once baked. The family liked it.\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "\n",
      "-  I am baking this for the 5th time as I type! Great recipe...moist and delicious. I add only 3/4c. sugar (brown) and a touch more salt along with the 4th banana and walnuts. It turns out perfectly every time.\n",
      "\n",
      "-  Absolutely delicious. I subbed half the sugar for brown sugar, and added a pinch of cinnamon and some walnuts and it was sooooo good. I havenât tried many banana bread recipes, but this one leaves nothing to be desired and Iâm sure itâll be my go to from here on out. It is MOIST.\n",
      "\n",
      "-  wow, this recipe is amazing! my family literally fights over who gets the last piece! it's super delicious, and the banana flavor is amazing. i also have a few tweaks to make this recipe better! i added brown instead of white sugar, and i also didn't use a whole stick of butter. i used about 7/8 of the stick. i would recommend using 4 bananas, they make the bread more moist and the banana flavor is more strong. i also would recommend using the vanilla, even though it says optional. but, i used a whole teaspoon instead of half. last, but not least, are the things to add into the batter! i add a handful of mini chocolate chips and walnuts. i also bought a cinnamon and sugar mix-in for this bread. that mix-in makes the bread a whole lot better! i would definitely recommend this recipe, it's the best one i've tried!\n",
      "\n",
      "-  Super yummy and moist!! I substituted the butter for cinnamon applesauce. And added some walnuts. I also made one with no walnuts for my son. I doubled the batter and that made two loaves and 18 muffins. Next time I will add zucchini.\n",
      "\n",
      "-  I have made this recipe numerous times over the last 3-4 years. It is the PERFECT banana bread recipe. Adjustments I made were using 1/4 cup brown sugar and 3/4 cane sugar, as well as adding cinnamon, nutmeg, and walnuts. I have made it with chocolate chips before as well - every version will come out delicious if you stick to the base recipe! Be sure to use the 4 bananas- itâs worth it!\n",
      "\n",
      "\n",
      "Cluster 4:\n",
      "\n",
      "-  I've made this recipe over and over again and it's always delish!!\n",
      "\n",
      "-  A great recipe for sure i love it.\n",
      "\n",
      "-  Just made this and it was a hit! Loved it.\n",
      "\n",
      "-  I usually don't rate anything but this turned out soooo good I had to. In love perfect recipe. I will never look for another one. Everyone loved it\n",
      "\n",
      "-  Wonderful Recipe every time I make it everyone prasises me a lot thank you for the wonderful recipe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, reviews in enumerate(closest_reviews):\n",
    "    print(f\"\\nCluster {i+1}:\\n\")\n",
    "    for j in range(len(reviews)):\n",
    "        print('- ', closest_reviews[i][j] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a509552-995f-4276-ab85-9b56de4d26e6",
   "metadata": {},
   "source": [
    "We can see how:  \n",
    "the first cluster talks about positive personal stories  \n",
    "the second cluster is mainly about complaints  \n",
    "the third cluster talks about modifications to the recipe  \n",
    "the fourth cluster are short compliments of the recipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_gpu)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
